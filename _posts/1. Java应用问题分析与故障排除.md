## 1. Java应用问题分析与故障排除

### 1.1 性能瓶颈分析

**1.常见的性能陷阱**

* 1.常见的性能现象：
  * 1.无响应
  * 2.运行缓慢
* 2.导致现象的问题：
  * 1.不良架构
  * 2.不恰当的线程同步
  * 3.资源争用
  * 4.不恰当的虚拟机参数
  * 5.缓慢的磁盘和网络IO
  * 6.内存泄露

**2.性能设计和调优的原则**

* 三个原则

  * 80-20原则

    20%的代码消耗了80%的资源，20%的代码消耗了80%的时间

  * 动态原则

    瓶颈是动态的，不同的使用条件瓶颈可能不同

  * 分级原则

    只有解决了当前的瓶颈，下一个瓶颈有可能出现

* 系统上线前理想的步骤：

  压力测试-->瓶颈分析-->优化调整-->回归验证

**3.问题源头**

* 部署问题
  * 不合理的负载分配
  * 通信效率低下
    * 网速慢，带宽不够
    * 发的数据包过大，解析起来过慢
  * 参数配置不当（连接池、线程池、JVM等）
  * 日志级别（有可能引起太高的磁盘IO，引起系统缓慢）
* 设计问题
  * 同步/异步使用不当
  * 缺乏必要的缓冲设计
  * 并发设计不当--资源争用
* 编码问题
  * 过大的同步范围
    * 事务过大需要拆成小事务
  * 效率低下的SQL语句
    * 比如没有建索引等
  * 全局集合对象
    * 把大量的对象都放到全局集合中，导致内存越来越大，而gc无法回收全集集合这些对象，久而久之，就会导致内存溢出，导致系统宕机。
  * 非线程同步设计问题
    * 编码时锁住了大量对象，而这些对象没有被释放，导致线程死锁，甚至有些代码中出现死循环。
  * String+

### 1.2 线程堆栈分析

**1.线程堆栈分析介绍**

* 1.概念

  线程堆栈也称作线程调用的堆栈，是虚拟机运行的时候线程状态的一个瞬间的快照。它采用了文本的方式记录了系统在某一时刻所有线程的运行状态；包括每一个线程的调用堆栈，和锁的所持有情况。

  不同的虚拟机打印出来的格式稍有不同，但是线程堆栈的信息大同小异，包括线程的名字，线程的id，线程的数量，线程的运行状态，锁的状态，还有线程调用堆栈的情况（包括执行的方法，执行源代码的行数）。

* 2.技术原理

  通过分析JVM线程运行情况，定位性能问题。

* 3.解决问题

  * 资源争用
  * 业务死锁
  * 系统挂起没有响应
  * CPU资源过高

* 4.使用场景

  识别高负载条件的性能瓶颈

* 5.不适用场合

  但操作时耗时，如一次点击，感觉迟缓

**2.如何输出线程堆栈**

* 输出堆栈的3种方法

  * Windows：在运行JAVA的控制台上按ctrl+break组合键

  * Unix：使用Kill -3 <javapid>输出到启动的java控制台或日志

  * 在jdk安装的bin目录下有两个程序jps和jstack（jstack <pid> >>filename）

    ![](F:\myNewBlob\Anarkh-Lee.github.io\_posts\img\jps_jstack.png)

* 得到了线程堆栈，主要分析要点
  * 线程死锁
  * CPU过高
  * 资源不足
  * 性能缓慢
  * 异常退出

**3.线程状态**

![](.\img\线程状态.png)

* Runnable：从虚拟机的角度看，Runnable状态代表线程正处于运行状态。通常情况下，处于运行状态下都会消耗cpu，但不是所有的Runnable状态都会消耗cpu，比如线程正在进行网络I/O的时候，这时，线程的状态是挂起的，不会调用java的sleep()或者wait()这些方法导致线程进入waiting状态，只有大量数据要进行处理时，才会消耗cpu。

* 死锁，Deadlock（重点关注）

* 执行中，Runnable

* 等待资源，Waiting on condition（重点关注）

  表示这个线程正在等待另外一个条件的发生来把自己唤醒，或者调用了sleep()，如果大量的线程处于Waiting on condition状态，很可能是这些线程都正在获取第三方资源（第三方网络资源、第三方数据库连接资源），但是迟迟获取不到应答，导致这些线程进入了等待状态。

* 等待获取监视器，Waiting on monitor entry（重点关注）

  线程正在执行Object.wait()方法。只有当线程获得了monitor，如果发现线程继续运行的条件没有满足，就调用Object.wait()方法，放弃了monitor。一般这种线程都是rmi相关线程或者是gc的线程，这种一般不是故障发生的点。

* 暂停，Suspended

* 对象等待中，Object.wait()或TIMED_WAITING

* 阻塞，Blocked（重点关注）

  等待进入了一个临界区。如果大量的线程处于了Blocked状态，而且还有waiting on monitor entry这种字样，就很可能是一个全局锁，锁住了大量的线程，也就是通常说的线程锁。

  介绍一下死锁：多个线程都在争夺同一个资源，这种情况下，JVM通常会自己检测出来。在现象上：卡住了、空白页、线程挂起。

* 停止挂起，Parked

**4.线程堆栈解读**

![](.\img\线程堆栈分析.png)

解读如下：

* 线程T1和T2均在等待资源状态（waiting for monitor entry）发生了线程阻塞。

* T2运行在DeadLock.java的第40行，在等待<0x22a297a8>对象释放锁，并锁定了<0x22a297b0>对象。

* T1运行在DeadLock.java的第25行，在等待<0x22a297b0>对象释放锁，并锁住了<0x22a297a8>对象。

  由上述解读，可以确定代码发生了线程死锁，并可以确定产生了死锁的代码行数。

### 1.3 内存溢出分析

内存溢出分为两种情况：

* 发生了内存泄露
* 虽然没有发生内存泄露，但是内存使用的增长太快了，比java虚拟机回收的速度还要快，这样也会导致内存不够用。

**1.内存溢出分析-介绍**

**1.1分析方法**

* 通过观察对象的数据和分配的位置，找到大量占用内存的对象。

**1.2发生现象**

* 长时间运行后无法提供服务
* JVM宕机（Core Dump）

**1.3解决方案**

* 全局集合-避免把临时对象放入全局集合
* 缓存-不用的对象及时清理
* Runnable对象生成后要及时使用，避免产生太多的线程

**2.内存溢出分析-原理**

内存泄露和内存溢出的关系：

只有内存泄露达到一定程度才会引起内存溢出。

内存溢出是如何产生的？

编写程序当中，编写到了一些代码，这些代码使用对象的时候，放入到了java虚拟机内存回收无法回收的区域，而这种代码被调用的次数又很多，那么就会导致越来越多的java虚拟机内存没有办法被它的回收器回收，这样内存的占用就越来越大，直到内存装不下这些对象，就会产生内存溢出，应用就无法工作，产生宕机。此时在JVM的安装目录下还会产生大量的Core Dump文件。

**2.1如何产生**

* 系统中存在越来越多的无用对象和根对象之间存在引用关系
* 对象产生过快
* 内存泄露产生了

**2.2如何消除**

* 截断系统中无用对象和根对象之间的引用关系
* 控制大对象产生的速度
* JVM可正常回收它们

**2.3常见原因**

* 对象存入全局HashMap，用完没有及时remove掉
* Thread只new了，但没有start
* 产生对象太大，内存装不下
* ...

**3.内存溢出分析-确认**

**3.1观察现象**

![](.\img\内存溢出分析现象.png)

* 应用程序无法运行
* 应用日志出现OutOfMemoryError
* JRE或应用程序路径出现大量的heap dump和Core Dump文件。

**3.2测试方法**

![](.\img\内存溢出现象测试方法FullGC.png)

* 多次执行Full GC操作
* 每次Full GC后，JVM的已使用内存比上次越来越多

能否在系统运行时检测出系统是否有内存溢出的可能性呢？

系统运行时可以每隔一段时间做一次Full GC操作（Full GC操作可能会导致用户使用系统时卡一下，应该在用户使用比较少的时候做），多次运行Full GC操作之后呢，看是不是每次Full GC之后，JVM的已使用内存比上次的越来越多，越来越多就代表有一部分对象在Full GC当中没有被清理掉，这种现象就有可能出现内存泄漏，导致内存溢出。

**4.内存溢出分析-定位**

* 1.在系统运行平稳后，做一次垃圾回收，并进行标记；

* 2.反复进行可能出现内存泄漏的操作，然后再进行一次垃圾回收；

* 3.观察并记录哪些对象是增加的最多的；

* 4.重复进行上面的操作，找出一直是增加的对象；这些对象可能是导致内存泄漏的原因；

* 5.通过工具的下钻打开一直增加的对象，将显示这些对象是由哪些类创建的。

  ![](.\img\内存溢出分析-定位1.png)

  ![](.\img\内存溢出分析-定位2.png)

### 1.4 常用工具使用

**常用工具使用-JVM工具**

* 命令行工具
  * Jstat（关注GC的次数和GC消耗时间）
  * Jmap（获取内存镜像）
  * HeapAnalyzer（内存分析工具，定位内存当中哪些对象占用最多，这是对象是由哪些类创建出来的，从而定位代码）
* 图形化工具
  * JVisualVM
  * Jconsole

**1.4.1常用工具使用--jstat**

工具都在jvm安装目录的bin目录下

![](.\img\jstat.png)

从上图中可以计算得到如下值：

1.年青代GC发生了1989次（YGCT）,共耗费了41.001秒（YGC），故年青代每次GC的时间为：41.001/1989=0.020秒。

2.完全GC发生了1次（FGCT），共耗费了0.971秒（FGC），故完全GC每次GC的时间为：0.971/1=0.971秒。

一般性能较好的判断：YGC耗时在50-100ms以内，FGC小于1秒以内。

如果GC非常频繁，不管是YGC还是FGC，都要关注内存对象产生的是不是过快了。

**1.4.2常用JVM工具--jmap**

```
jmap -dump: format=b, file=testjvm.dump $vmid$
```

vmid是java应用的进程id号，file: java:堆内存数据保存为文件的名称。

以上的命令可以将当前JAVA内存堆保存为文件，便于进一步进行分析。

特别注意：

jmap会把整个内存的镜像存到硬盘上，会在很短的时间内向硬盘写入大量内容。进行此工作的时候，应用访问可能会中断。所以不应该在业务运行状态下操作此命令。

**1.4.3常用工具使用--HeapAnalyer**

通过jmap得到了堆运行镜像文件之后，可以使用HeapAnalyer工具来进行内存镜像的分析。

![](.\img\HeapAnalyer.png)

命令行：

```
java -Xmx800m -jar ha395.jar
```

注意：-Xmn800m是指定工具所需的java堆大小，此值要大于分析文件的尺寸大小，如果启动过程中发现控制台有java.lang.OutOfMeemoryError出现，可以适当加大上面的数字800，给予更多的空间。ha395.jar中的文件名称按实际下载解压后的文件名为准。

**1.4.4常用工具使用--JVisualVM**

![](.\img\JVisualVM.png)

JDK1.6以后提供（之前可以使用Jconsole）

如果是远程的机器没有图形界面，我们也想监控它的JVM内存或者用图形化监控它的参数，在运行情况需要怎么办？

可以按照下面方法配置一个JAVA_OPTS参数，然后启动它的jmxremote.rmi远程调用这种方式，就可以连接上远程的JVM，实时观察现象。

配置方法：

应用启动参数增加

```
JAVA_OPTS="-

Djava.rmi.server.hostname=127.0.0.1 -

Dcom.sun.management.jmxremote.port=80

99 -

Dcom.sun.management.jmxremote.rmi.port

=8099 -

Dcom.sun.management.jmxremote.ssl=false

-

Dcom.sun.management.jmxremote.authenti

cate=false"
```

### 1.5 故障排除案例

**1.5.1故障排除案例--CPU占用率高**

![](.\img\CPU占用率高.png)

* 1.问题表现

  某系统上线前部署后，在没有访问压力的情况下，启动后即出现单位CPU资源占满，几天后无法访问。

* 2.问题分析

  上述现象一般是系统中出现了类似死循环的业务逻辑且长时间运行所致，应找到其对应的运行进程，如果可能，应进一步找到其执行代码。

* 3.排查步骤

  * 使用TOP命令查看，发现进程号为17733的java进程占满多个CPU资源
  * 对进程执行`top -H -p`进行细分查看发现nid为17772和18156的子进程占满单个CPU资源
  * 将占用CPU的17772和18156进程号转为16进制数，分别为46ec和456c
  * 在TheadDump中查找进程中运行的方法
  * 找到运行的方法对应代码行，交给开发人员排查代码

* 4.解决效果

  代码中出现死循环业务逻辑，且该段代码未做控制，随时间推移导致多个CPU资源占满，系统无法运行。经现场开发人员修改系统代码后。此问题不再出现。

**1.5.2故障排除案例--运行缓慢**

![运行缓慢](.\img\运行缓慢.png)

* 1.问题表现

  某系统与其上线后将有大量用户访问，性能测试登录后200用户同时登录响应时间达到了20秒，不满足性能要求。

* 2.问题分析

  应用和数据库服务器硬件资源占用很低，从应用方面进行性能瓶颈跟踪。

* 3.排查步骤

  * 捕获线程堆栈后，发现大量的线程处于阻塞，其执行为等待获得数据库连接池中的连接。对应用系统数据库连接参数进行调整后，业务响应时间下降到8秒，但仍未满足业务需求（响应时间3秒内）。
  * 重新采集线程dump查看线程发现线程阻塞问题消失，查看调用方法，大部分线程都在做取redis内容的操作。通过逐个对Redis对象存取排查，发现从redis获取组织和权限树时存取缓慢。组织和权限是一个4层的树形数据结构。大小超过1M，每次存取Redis都要序列化和反序列化，生成对象效率很低。
  * 考虑如果树对象的修改很少，每次修改时向redis存入时间戳，取时先比较时间戳，发生变化时再重取对象，可以大幅减少树对象获取次数。

* 4.解决效果

  经过上述调优步骤，登录并方位首页在200用户同时访问时响应时间下降到0.5秒，满足系统预期要求。

**1.5.3故障排除案例--系统无响应**

![](.\img\系统无响应.png)

* 1.问题表现

  某系统正式上线运行以来，应用服务器偶尔会出现宕机故障，导致宕机的Server节点失去响应。

* 2.问题分析

  查看应用相关日志，没有发现明显的异常情况，查看故障发生时应用中间件JVM截图，有大量GC活动和长时间CPU占用，怀疑出现内存不足。

* 3.排查步骤

  * 采集Java Thread Dump，采集方法每隔5秒左右执行一次，共采集了9次
  * 在9次Thread Dump中，有一个线程持续运行一个业务方法。编号为ExecuteThread：'9'的线程持续运行32秒没有完成
  * 运行的业务方法中使用额JDBC的ScrollableResultSet对象，可滚动的结果集需要在JVM内存中缓存数据对象，因此当查询最后一页的数据时，不仅需要遍历全部的查询结果还需要缓存全部的查询结果，因此当查询的数据量过大时，对中间件的CPU和JVM内存占用都非常大，使得业务系统失去响应，而且有使JVM发生内存溢出OOM错误的风险。

* 4.解决效果

  将USE_OPTIMIZE_PAGING_SQL参数修改为true，使用数据库翻页，页面响应时间大大缩短，在翻页操作的执行过程中，业务系统其它功能可以正常使用，故障解决。

**1.5.4故障排除案例--内存溢出**

![](.\img\内存溢出.png)

* 1.问题表现

  某在线学习系统项目按合同的要求有Tomcat环境迁移至WAS环境后，在用户使用（无并发）过程中多次出现应用服务器宕机导致项目无法顺利验收

* 2.问题分析

  通过查看服务日导，发现WAS的Profiles目录下已存在大量的javacore和heapdump文件。系统发生了JVM内存溢出导致应用服务器重启

* 3.排查步骤

  * 设置JVM堆最大值为1024m，启动后系统占用JVM堆内存约为600M，分别播放一个200M课件和一个700M课件，使用工具监控JVM内存使用情况。
  * 下载完200课件后，系统可以正常访问，JVM堆使用增加200M
  * 下载700M课件过程中，系统发生内存溢出，应用服务器无法访问，JVM工具无法进行监控。
  * 由上述现象分析，WAS在用户下载课件文件时，尝试将整个课件文件全部调入JVM后再推送给用户，导致JVM内存溢出。
  * 经查相关文档，确认WAS下载大文件时，会将文件读取到jvm，导致jvm发生内存溢出现象。

* 4.解决效果

  对于WAS曾出现过内存溢出，并且存在文件下载情况的，建议设置一下参数：应用程序服务器->server1->web容器->定制属性，输入"com.ibm.ws.webcontainer.channelwritetype"值"sync"

  按上述步骤设置该参数后。同时下载4个700M课件，系统JVM堆大小无明显增长，系统正常访问，问题得以解决。

